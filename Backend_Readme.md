# Context_Lens_Ragger Backend

## Overview
The Context_Lens_Ragger backend is designed to handle document processing, storage, and retrieval, enabling the generation of comprehensive answers and descriptions based on the content of uploaded documents. The backend leverages a variety of advanced technologies including OpenAI's GPT-3.5, Tesseract OCR, and Chroma for vector storage. It also supports feedback mechanisms and document management via a RESTful API.

## Features
- **Document Processing**:
    - **Supported File Types**: Handles PDFs, DOCX, PNG, JPG, JPEG, and SVG files.
    - **Text Extraction**: Uses Tesseract OCR for extracting text from images.
    - **Image Captioning**: Utilizes the BLIP model to generate image captions.
    - **SVG Handling**: Converts SVG files to PNG using `rsvg-convert` before further processing.
- **Question Answering**:
    - **Flexible Model Integration**: Uses models like Ollama's "mistral" for response generation, with support for integrating other models such as GPT-3.5.
    - **Contextual Answering**: The system cites relevant sections from documents, ensuring well-supported and accurate answers.
- **Chroma Document Store**:
    - **Efficient Retrieval**: Stores and retrieves documents using the Chroma vector store, supporting embedding-based search.
    - **Document Management**: Provides API routes for uploading, viewing, and deleting documents.
- **Evaluation Chain**:
    - **Performance Assessment**: Includes an evaluation script that uses LangSmith to assess model performance on custom datasets.
- **Environment Configuration**:
    - **Easy Setup**: Configurable via environment variables for API keys, database connections, and tracing.
    - 
## API Routes
The backend exposes several RESTful API routes:

- **Upload Document**: `POST /upload-document/`  
  Upload a document file for processing and indexing into the Chroma vector store.

- **Fetch Documents**: `GET /documents/`  
  Retrieve a list of all uploaded documents with their metadata.

- **Delete Document**: `DELETE /documents/{document_id}`  
  Delete a document by its unique ID and remove its embeddings from the Chroma vector store.

- **Upload Directory**: `POST /upload-directory/`  
  Process and upload all documents within a specified directory.

- **Send Feedback**: `POST /feedback`  
  Submit feedback for a specific run or process.

- **Update Feedback**: `PATCH /feedback`  
  Update existing feedback with new comments or scores.

- **Get Trace**: `POST /get_trace`  
  Retrieve the trace URL for a specific LangSmith run.

## Database Models
- **DocumentMetadata**: Stores metadata related to uploaded documents, including file name, location, embedding IDs, and timestamps.

  ```python
  class DocumentMetadata(Base):
      __tablename__ = "document_metadata"

      id = Column(SQLAlchemyUUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
      filename = Column(String, nullable=False)
      user_id = Column(SQLAlchemyUUID(as_uuid=True), nullable=True)
      file_location = Column(String, nullable=False)
      document_metadata = Column(Text, nullable=True)
      embedding_ids = Column(ARRAY(String), nullable=True)
      created_at = Column(DateTime, server_default=func.now())
  ```

## In-depth Explanation of `ingest_service.py` and `rag_service.py`

### 1. `ingest_service.py`

The `ingest_service.py` file is responsible for processing, indexing, and managing documents within the backend. It performs several key tasks including extracting content from various file types, generating detailed captions for images, and storing document embeddings in the Chroma vector store.

#### Key Components:
- **Document Processing**:
    - **Supported File Types**: The service supports PDFs, DOCX, images (PNG, JPG, JPEG), and SVG files. Each file type has a specific processing method:
        - **PDF**: Processed using the `PyPDFLoader` to extract text content.
        - **DOCX**: Processed using `Docx2txtLoader` to extract text content.
        - **Images**: Processed using `UnstructuredImageLoader` for general images, and a special `process_svg` method for SVG files.
        - **SVG to PNG Conversion**: SVG files are converted to PNG using `rsvg-convert` before further processing.

- **Text Extraction**:
    - **Tesseract OCR**: Used to extract text from images. The extracted text is then combined with a detailed caption generated by a vision-language model (BLIP).

- **Image Captioning**:
    - **BLIP**: Uses the BLIP model to generate captions for images. These captions are then further enriched by using OpenAI's GPT-3.5 model to produce comprehensive descriptions.

- **Document Ingestion**:
    - Documents are split into smaller chunks using `RecursiveCharacterTextSplitter` to facilitate efficient processing and embedding.
    - Embeddings are generated using the `OllamaEmbeddings` model and stored in the Chroma document store.

- **Error Handling**:
    - The service includes robust error handling to manage exceptions during file processing, embedding generation, and storage.

#### Flow:
1. **File Upload**: A file is uploaded via the API.
2. **File Processing**: Depending on the file type, the appropriate loader or method is called to extract the content.
3. **Text Extraction & Captioning**: If the file is an image, text is extracted using OCR, and a caption is generated using BLIP.
4. **Content Description**: The extracted text and generated caption are combined and sent to GPT-3.5 for a comprehensive description.
5. **Indexing**: The processed content is then split into chunks, embeddings are generated, and the document is stored in the Chroma vector store.
6. **Feedback Loop**: Users can provide feedback on the generated content, which is used to improve future processing.

### 2. `rag_service.py`

The `rag_service.py` file is focused on implementing a retrieval-augmented generation (RAG) approach, which is designed to retrieve relevant document sections and generate answers or descriptions based on them. It leverages LangChainâ€™s capabilities to manage the flow of information from retrieval to generation.

#### Key Components:
- **Retriever Chain**:
    - **Condense Question**: This component rephrases follow-up questions into standalone questions to ensure clarity.
    - **Retrieval**: The rephrased question is used to query the Chroma document store to retrieve the most relevant document sections.

- **Response Generation**:
    - **Model Integration**: The system uses a configurable model, like Ollama's "mistral", to generate a concise and informative response based on the document content.
    - **Contextual Answering**: The system is designed to cite the relevant sections of the document, ensuring that answers are well-supported and contextually accurate.

- **Document Formatting**:
    - The retrieved documents are formatted for easy consumption by the language model, ensuring that the content is presented in a way that optimizes the accuracy of the generated answers.

#### Flow:
1. **Question Input**: The user submits a question via the API.
2. **Condense Question**: If the question is part of a longer conversation, it is condensed to a standalone query.
3. **Document Retrieval**: The standalone question is used to retrieve the most relevant document sections from the Chroma vector store.
4. **Response Generation**: The retrieved document sections are fed into the language model (e.g., "mistral") to generate a detailed and accurate response.
5. **Citing Sources**: The generated answer includes citations from the retrieved documents to support the response.
6. **Return Response**: The final answer is returned to the user.

### Backend Flow Overview

1. **Document Upload and Ingestion**:
    - When a user uploads a document, it is processed by the `ingest_service.py` where the text is extracted, captions are generated, and embeddings are stored in Chroma.

2. **Question Answering**:
    - When a user submits a question, `rag_service.py` takes over. It retrieves relevant document sections, uses the selected model (e.g., "mistral") to generate a comprehensive answer, and returns the response to the user.

3. **Document Management**:
    - Users can view, delete, and manage their uploaded documents via the API routes defined in the backend.

4. **Feedback and Evaluation**:
    - The system supports feedback submission to improve model responses and includes evaluation capabilities for assessing model performance on custom datasets.